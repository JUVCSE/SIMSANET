{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6453494,"sourceType":"datasetVersion","datasetId":3726042}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"train_dir = \"/kaggle/input/stanford196-croppedtraintest/Stanford196_BaseDir_CroppedTrain/content/base_dir\"\ntest_dir = \"/kaggle/input/stanford196-croppedtraintest/Stanford196_BaseDir_CroppedTest/content/base_dir_test\"","metadata":{"id":"Z9CkzTAjG59r","execution":{"iopub.status.busy":"2024-08-16T18:54:40.474491Z","iopub.execute_input":"2024-08-16T18:54:40.474843Z","iopub.status.idle":"2024-08-16T18:54:40.486853Z","shell.execute_reply.started":"2024-08-16T18:54:40.474814Z","shell.execute_reply":"2024-08-16T18:54:40.485443Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout, InputLayer, BatchNormalization, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\nfrom keras import regularizers\nfrom keras import backend as K","metadata":{"id":"CrVVId06vR1A","outputId":"aaadbc1e-1609-47ed-d86c-6cc3fce63f92","execution":{"iopub.status.busy":"2024-08-16T18:54:40.863660Z","iopub.execute_input":"2024-08-16T18:54:40.864500Z","iopub.status.idle":"2024-08-16T18:54:53.391361Z","shell.execute_reply.started":"2024-08-16T18:54:40.864460Z","shell.execute_reply":"2024-08-16T18:54:53.390575Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-16 18:54:43.115523: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-16 18:54:43.115623: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-16 18:54:43.248155: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"img_width, img_height = 400, 400\nbatch_size = 16\nepochs = 100\nnum_classes = 196","metadata":{"id":"hH0SAjDmKY09","execution":{"iopub.status.busy":"2024-08-16T18:54:53.393073Z","iopub.execute_input":"2024-08-16T18:54:53.393944Z","iopub.status.idle":"2024-08-16T18:54:53.399069Z","shell.execute_reply.started":"2024-08-16T18:54:53.393910Z","shell.execute_reply":"2024-08-16T18:54:53.398067Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator( rescale=1./255, rotation_range=25, width_shift_range=0.25,\n                                   height_shift_range=0.25, shear_range=0.25, zoom_range=0.25,\n                                   horizontal_flip=True, fill_mode='nearest' )\n\n\ntest_datagen = ImageDataGenerator(rescale=1.0 / 255)\n\ntrain_generator = train_datagen.flow_from_directory( train_dir,\n                                                    target_size=(img_width, img_height),\n                                                    batch_size=batch_size, class_mode='categorical',\n                                                    shuffle=True)\n\ntest_generator = test_datagen.flow_from_directory( test_dir,\n                                                  target_size=(img_width, img_height),\n                                                  batch_size=batch_size, class_mode='categorical',\n                                                  shuffle=False )","metadata":{"id":"VeuMqX4EKdeq","outputId":"594018f2-1de1-4f3d-c0dc-6fdceda84e42","execution":{"iopub.status.busy":"2024-08-16T18:54:53.402114Z","iopub.execute_input":"2024-08-16T18:54:53.404210Z","iopub.status.idle":"2024-08-16T18:54:54.260209Z","shell.execute_reply.started":"2024-08-16T18:54:53.404143Z","shell.execute_reply":"2024-08-16T18:54:54.259416Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 8144 images belonging to 196 classes.\nFound 8041 images belonging to 196 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\nfrom tensorflow.keras.layers import *","metadata":{"id":"Upd4zQZDKd5f","execution":{"iopub.status.busy":"2024-08-16T18:54:54.262901Z","iopub.execute_input":"2024-08-16T18:54:54.263330Z","iopub.status.idle":"2024-08-16T18:54:54.267665Z","shell.execute_reply.started":"2024-08-16T18:54:54.263298Z","shell.execute_reply":"2024-08-16T18:54:54.266813Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"num_heads = 5\nreduction_ratio = 8\ndropout_rate = 0.02\nl2_reg = 0.001\nsimam_lambda = 0.0001","metadata":{"id":"WVecAUOYvR1G","execution":{"iopub.status.busy":"2024-08-16T18:54:54.268814Z","iopub.execute_input":"2024-08-16T18:54:54.269077Z","iopub.status.idle":"2024-08-16T18:54:54.294107Z","shell.execute_reply.started":"2024-08-16T18:54:54.269055Z","shell.execute_reply":"2024-08-16T18:54:54.293267Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nclass SimAM(tf.keras.layers.Layer):\n    def __init__(self, eps=0.0001, activation=tf.nn.sigmoid, trainable=True, name=None, **kwargs):\n        super(SimAM, self).__init__(name=name, trainable=trainable, **kwargs)\n        self.activation = activation\n        self.eps = eps\n\n    def build(self, input_shape):\n        self.height, self.width, self.channels = input_shape[1], input_shape[2], input_shape[3]\n        self.norm = 4. / (self.height * self.width - 1)\n        super().build(input_shape)\n\n    def call(self, inputs, **kwargs):\n        minus_mu_square = tf.square(inputs - tf.reduce_mean(inputs, axis=(1, 2), keepdims=True))\n        out = minus_mu_square / tf.maximum(\n            tf.reduce_sum(minus_mu_square, axis=(1, 2), keepdims=True) * self.norm,\n            self.eps) + 0.5\n        return inputs * self.activation(out)","metadata":{"id":"QyTrKmX1vR1H","execution":{"iopub.status.busy":"2024-08-16T18:54:54.295160Z","iopub.execute_input":"2024-08-16T18:54:54.295535Z","iopub.status.idle":"2024-08-16T18:54:54.309114Z","shell.execute_reply.started":"2024-08-16T18:54:54.295509Z","shell.execute_reply":"2024-08-16T18:54:54.308382Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CSA(layers.Layer):\n    def __init__(self, num_heads, channels, dropout_rate=0.02,l2_reg=0.001, **kwargs):\n        super(CSA, self).__init__(**kwargs)\n        self.num_heads = num_heads\n        self.head_channels = channels // num_heads\n        self.heads = []\n\n        for _ in range(num_heads):\n            self.heads.append(self.build_SA_block(channels=self.head_channels,\n                                                              dropout_rate=dropout_rate,\n                                                              l2_reg=l2_reg))\n\n        self.simam = SimAM(eps=0.0001, activation=tf.nn.sigmoid)\n        self.dropout = layers.Dropout(dropout_rate)\n        self.batch_norm = layers.BatchNormalization()\n\n    def build_SA_block(self, channels, dropout_rate, l2_reg):\n        input_tensor = tf.keras.Input(shape=(6, 6, channels))\n\n        # Channel-wise attention Global features\n        input_channels = channels\n\n        conv_before_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(input_tensor)\n\n        conv_before_attention1 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention0)\n\n        conv_before_attention2 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention0)\n\n        conv_before_attention3 = Multiply()([conv_before_attention1, conv_before_attention2])\n\n        conv_before_attention4 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention3)\n\n        conv_before_attention5 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention3)\n\n        conv_before_attention6 = Multiply()([conv_before_attention4, conv_before_attention5])\n\n        conv_before_attention7 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention6)\n\n        conv_before_attention8 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention6)\n\n        conv_before_attention9 = Multiply()([conv_before_attention7, conv_before_attention8])\n\n        conv_before_attention10 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention9)\n\n        conv_before_attention11 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention9)\n\n        conv_before_attention12 = Multiply()([conv_before_attention10, conv_before_attention11])\n\n        conv_before_attention12 = Dropout(dropout_rate)(conv_before_attention12)\n\n        avg_pool = GlobalAveragePooling2D()(conv_before_attention12)\n        max_pool = GlobalMaxPooling2D()(conv_before_attention12)\n        concat = Concatenate()([avg_pool, max_pool])\n\n        sequential_attention = Reshape((1, 1, concat.shape[-1]))(concat)\n        sequential_attention = Lambda(lambda x: tf.keras.backend.repeat_elements(x, rep=6, axis=1))(sequential_attention)\n        sequential_attention = Lambda(lambda x: tf.keras.backend.repeat_elements(x, rep=6, axis=2))(sequential_attention)\n\n        sequential_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                                       depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                       padding='same')(sequential_attention)\n\n        sequential_attention1 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention0)\n\n        sequential_attention2 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention0)\n\n        sequential_attention3 = Multiply()([sequential_attention1, sequential_attention2])\n\n        sequential_attention4 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention3)\n\n        sequential_attention5 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention3)\n\n        sequential_attention6 = Multiply()([sequential_attention4, sequential_attention5])\n\n        sequential_attention7 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention6)\n\n        sequential_attention8 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention6)\n\n        sequential_attention9 = Multiply()([sequential_attention7, sequential_attention8])\n\n        sequential_attention10 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention9)\n\n        sequential_attention11 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention9)\n\n        sequential_attention12 = Multiply()([sequential_attention10, sequential_attention11])\n\n        sequential_attention12 = Dropout(dropout_rate)(sequential_attention12)\n\n        sequential_attention13 = Concatenate()([conv_before_attention12, sequential_attention12])\n\n        # Row-wise attention\n        row_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        row_attention1 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention0)\n\n        row_attention2 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention1)\n\n        row_attention3 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention2)\n\n        row_attention4 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention3)\n\n        row_attention4 = Dropout(dropout_rate)(row_attention4)\n\n        row_attention5 = Concatenate()([sequential_attention13, row_attention4])\n\n        # Column-wise attention\n        col_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        col_attention1 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention0)\n\n        col_attention2 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention1)\n\n        col_attention3 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention2)\n\n        col_attention4 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention3)\n\n        col_attention4 = Dropout(dropout_rate)(col_attention4)\n\n        col_attention5 = Concatenate()([sequential_attention13, col_attention4])\n\n        # Combine row and column attentions\n        sequential_attention14 = Multiply()([row_attention5, col_attention5])\n        sequential_attention14 = Dropout(dropout_rate)(sequential_attention14)\n\n        conv_after_attention0 = DepthwiseConv2D( kernel_size=(1, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(sequential_attention14)\n\n        conv_after_attention1 = DepthwiseConv2D( kernel_size=(1, 2), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention0)\n\n        conv_after_attention2 = DepthwiseConv2D( kernel_size=(2, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention0)\n\n        conv_after_attention3 = Multiply()([conv_after_attention1, conv_after_attention2])\n\n        conv_after_attention4 = DepthwiseConv2D( kernel_size=(1, 3), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention3)\n\n        conv_after_attention5 = DepthwiseConv2D( kernel_size=(3, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention3)\n\n        conv_after_attention6 = Multiply()([conv_after_attention4, conv_after_attention5])\n\n        conv_after_attention7 = DepthwiseConv2D( kernel_size=(1, 4), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention6)\n\n        conv_after_attention8 = DepthwiseConv2D( kernel_size=(4, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention6)\n\n        conv_after_attention9 = Multiply()([conv_after_attention7, conv_after_attention8])\n\n        conv_after_attention10 = DepthwiseConv2D( kernel_size=(1, 5), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention9)\n\n        conv_after_attention11 = DepthwiseConv2D( kernel_size=(5, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention9)\n\n        conv_after_attention12 = Multiply()([conv_after_attention10,\n                                                     conv_after_attention11])\n\n        conv_after_attention12 = Dropout(dropout_rate)(conv_after_attention12)\n\n        conv_after_attention12 = Concatenate()([conv_before_attention12, conv_after_attention12])\n\n        # Channel-wise attention local features\n        sequential_attention15 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                                       depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                       padding='same')(conv_after_attention12)\n\n        sequential_attention16 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention15)\n\n        sequential_attention17 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention15)\n\n        sequential_attention18 = Multiply()([sequential_attention16, sequential_attention17])\n\n        sequential_attention19 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention18)\n\n        sequential_attention20 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention18)\n\n        sequential_attention21 = Multiply()([sequential_attention19, sequential_attention20])\n\n        sequential_attention22 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention21)\n\n        sequential_attention23 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention22)\n\n        sequential_attention24 = Multiply()([sequential_attention22, sequential_attention23])\n\n        sequential_attention25 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention24)\n\n        sequential_attention26 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention24)\n\n        sequential_attention27 = Multiply()([sequential_attention25, sequential_attention26])\n\n        sequential_attention27 = Dropout(dropout_rate)(sequential_attention27)\n\n        sequential_attention28 = Concatenate()([conv_before_attention12, sequential_attention27])\n\n        # Row-wise attention\n        row_attention6= DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        row_attention7= DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention6)\n\n        row_attention8= DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention7)\n\n        row_attention9= DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention8)\n\n        row_attention10= DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention9)\n\n        row_attention10 = Dropout(dropout_rate)(row_attention10)\n        row_attention11 = Concatenate()([sequential_attention28, row_attention10])\n\n        # Column-wise attention\n        col_attention6= DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        col_attention7= DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention6)\n\n        col_attention8= DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention7)\n\n        col_attention9= DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention8)\n\n        col_attention10= DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention9)\n\n        col_attention10= Dropout(dropout_rate)(col_attention10)\n        col_attention11= Concatenate()([sequential_attention28, col_attention10])\n\n        # Combine row and column attentions\n        sequential_attention29=Multiply()([row_attention11, col_attention11])\n        sequential_attention29=Dropout(dropout_rate)(sequential_attention29)\n\n        conv_after_attention13 = DepthwiseConv2D( kernel_size=(1, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(sequential_attention29)\n\n        conv_after_attention14= DepthwiseConv2D( kernel_size=(1, 2), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention13)\n\n        conv_after_attention15= DepthwiseConv2D( kernel_size=(2, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention13)\n\n        conv_after_attention16=Multiply()([conv_after_attention14, conv_after_attention15])\n\n        conv_after_attention17= DepthwiseConv2D( kernel_size=(1, 3), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention16)\n\n        conv_after_attention18= DepthwiseConv2D( kernel_size=(3, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention16)\n\n        conv_after_attention19=Multiply()([conv_after_attention17, conv_after_attention18])\n\n        conv_after_attention20= DepthwiseConv2D( kernel_size=(1, 4), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention19)\n\n        conv_after_attention21= DepthwiseConv2D( kernel_size=(4, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention19)\n\n        conv_after_attention22=Multiply()([conv_after_attention20, conv_after_attention21])\n\n        conv_after_attention23= DepthwiseConv2D( kernel_size=(1, 5), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention22)\n\n        conv_after_attention24= DepthwiseConv2D( kernel_size=(5, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention23)\n\n        conv_after_attention25=Multiply()([conv_after_attention23,\n                                                   conv_after_attention24])\n\n        conv_after_attention25= Dropout(dropout_rate)(conv_after_attention25)\n\n        conv_after_attention25 = Concatenate()([conv_before_attention12, conv_after_attention25])\n\n        dual_sequential_attention = Concatenate()([conv_after_attention12, conv_after_attention25])\n\n        dual_sequential_attention = BatchNormalization()(dual_sequential_attention)\n        dual_sequential_attention = Dropout(dropout_rate)(dual_sequential_attention)\n\n        return tf.keras.Model(inputs=input_tensor, outputs=dual_sequential_attention)\n\n    def call(self, inputs):\n        head_outputs = []\n\n        for i in range(self.num_heads):\n            head_input = inputs[:, :, :, i * self.head_channels:(i + 1) * self.head_channels]\n            head_output = self.heads[i](head_input)\n            head_outputs.append(head_output)\n\n        cbam_attention = Concatenate()(head_outputs)\n        simam_attention = self.simam(inputs)\n\n        fused_attention = tf.concat([cbam_attention, simam_attention], axis=-1)\n        fused_attention = self.dropout(fused_attention)\n        fused_attention = self.batch_norm(fused_attention)\n\n        return fused_attention","metadata":{"id":"0rMv0R6mZHGg","execution":{"iopub.status.busy":"2024-08-16T18:54:54.310491Z","iopub.execute_input":"2024-08-16T18:54:54.310763Z","iopub.status.idle":"2024-08-16T18:54:54.393062Z","shell.execute_reply.started":"2024-08-16T18:54:54.310741Z","shell.execute_reply":"2024-08-16T18:54:54.392058Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Lambda, DepthwiseConv2D, BatchNormalization, Dropout, Reshape, UpSampling2D, Multiply","metadata":{"id":"3xVfYkKfvR1L","execution":{"iopub.status.busy":"2024-08-16T18:54:54.394375Z","iopub.execute_input":"2024-08-16T18:54:54.394758Z","iopub.status.idle":"2024-08-16T18:54:54.407184Z","shell.execute_reply.started":"2024-08-16T18:54:54.394726Z","shell.execute_reply":"2024-08-16T18:54:54.406051Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet201\n\nbase_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nx = base_model.output\nx = BatchNormalization()(x)\nx = Dropout(0.02)(x)\nprint(x.shape)\n\nx = layers.AveragePooling2D(pool_size=2)(x)\nx = BatchNormalization()(x)\nx = Dropout(0.02)(x)\nprint(x.shape)\n\nx = SeparableConv2D( 512, kernel_size=(5, 5), activation='sigmoid',\n            depthwise_initializer='he_normal', pointwise_initializer='he_normal',\n            depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n            pointwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n            padding='same')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.02)(x)\nprint(x.shape)\n\nx = CSA(num_heads, 512, dropout_rate, l2_reg)(x)\nx = BatchNormalization()(x)\nx = Dropout(0.02)(x)\nprint(\"attention\",x.shape)\n\nx = layers.GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.02)(x)\nprint(x.shape)\n\npreds = Dense(units=196, activation='softmax')(x)\nmodel1 = tf.keras.Model(inputs=base_model.input, outputs=preds)\n","metadata":{"id":"u2GMJO-QvR1M","outputId":"59b75acf-0892-41c1-c491-27f4209b46f8","execution":{"iopub.status.busy":"2024-08-16T18:54:54.408685Z","iopub.execute_input":"2024-08-16T18:54:54.409064Z","iopub.status.idle":"2024-08-16T18:55:10.890750Z","shell.execute_reply.started":"2024-08-16T18:54:54.409035Z","shell.execute_reply":"2024-08-16T18:55:10.889853Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n(None, 12, 12, 1920)\n(None, 6, 6, 1920)\n(None, 6, 6, 512)\nattention (None, 6, 6, 7142)\n(None, 7142)\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in model1.layers:\n    layer.trainable = True","metadata":{"id":"ptuIy8QqvR1N","execution":{"iopub.status.busy":"2024-08-16T18:55:10.893475Z","iopub.execute_input":"2024-08-16T18:55:10.893756Z","iopub.status.idle":"2024-08-16T18:55:10.902679Z","shell.execute_reply.started":"2024-08-16T18:55:10.893731Z","shell.execute_reply":"2024-08-16T18:55:10.901842Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model1.compile(optimizer=Adam(learning_rate = 0.0001), loss = 'categorical_crossentropy',\n              metrics=['accuracy','mse'])\n\ncheckpoint = ModelCheckpoint('DenseNet201_Modified_MHSimamCBAM_Stanford.weights.h5', monitor='val_accuracy',\n                             save_best_only = True, save_weights_only = True, mode ='max', verbose = 2)\n\nearly_stop = EarlyStopping(monitor = 'val_accuracy', patience = 8, mode = 'max', verbose = 2)\n\nreduce_learning_rate=ReduceLROnPlateau(monitor = \"val_accuracy\", factor = 0.1, patience = 4, verbose = 2)","metadata":{"id":"HjFvYz70vR1N","execution":{"iopub.status.busy":"2024-08-16T18:55:10.903721Z","iopub.execute_input":"2024-08-16T18:55:10.904003Z","iopub.status.idle":"2024-08-16T18:55:10.929252Z","shell.execute_reply.started":"2024-08-16T18:55:10.903979Z","shell.execute_reply":"2024-08-16T18:55:10.928397Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"total_params = model1.count_params()\nprint(f\"Total parameters in the model: {total_params}\")","metadata":{"id":"Pt1AsKAIvR1O","outputId":"7f85e059-7954-497b-f63e-682bb2f3bfca","execution":{"iopub.status.busy":"2024-08-16T18:55:10.930475Z","iopub.execute_input":"2024-08-16T18:55:10.931211Z","iopub.status.idle":"2024-08-16T18:55:10.949167Z","shell.execute_reply.started":"2024-08-16T18:55:10.931179Z","shell.execute_reply":"2024-08-16T18:55:10.948282Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Total parameters in the model: 21292216\n","output_type":"stream"}]},{"cell_type":"code","source":"trainable_params = tf.reduce_sum([tf.reduce_prod(v.shape) for v in model1.trainable_variables])\nprint(f\"Trainable parameters in the model: {trainable_params}\")","metadata":{"id":"yjl-NGrHvR1O","outputId":"06050ee6-842c-4b9a-a3a8-8ca0ac3ede50","execution":{"iopub.status.busy":"2024-08-16T18:55:10.950201Z","iopub.execute_input":"2024-08-16T18:55:10.950495Z","iopub.status.idle":"2024-08-16T18:55:11.861200Z","shell.execute_reply.started":"2024-08-16T18:55:10.950463Z","shell.execute_reply":"2024-08-16T18:55:11.860232Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Trainable parameters in the model: 20998344\n","output_type":"stream"}]},{"cell_type":"code","source":"non_trainable_params = tf.reduce_sum([tf.reduce_prod(v.shape) for v in model1.non_trainable_weights])\nprint(f\"Non-trainable parameters in the model: {non_trainable_params}\")","metadata":{"id":"Wev4McijvR1P","outputId":"4aad621a-8470-409f-d926-0a0acc3d67e3","execution":{"iopub.status.busy":"2024-08-16T18:55:11.862320Z","iopub.execute_input":"2024-08-16T18:55:11.862673Z","iopub.status.idle":"2024-08-16T18:55:12.149177Z","shell.execute_reply.started":"2024-08-16T18:55:11.862647Z","shell.execute_reply":"2024-08-16T18:55:12.148228Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Non-trainable parameters in the model: 293872\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\nhistory=model1.fit(train_generator, epochs = 50, validation_data = test_generator,\n                  callbacks = [checkpoint, early_stop, reduce_learning_rate])\n\nend_time = time.time()\npreprocessing_time = end_time - start_time\n\nprint(\"Preprocessing completed. Time taken:\", preprocessing_time, \"seconds\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T14:38:31.213434Z","iopub.execute_input":"2023-12-07T14:38:31.213847Z","iopub.status.idle":"2023-12-07T17:28:45.830594Z","shell.execute_reply.started":"2023-12-07T14:38:31.213820Z","shell.execute_reply":"2023-12-07T17:28:45.829654Z"},"id":"5wE-RGUEvR1P","outputId":"ad2b3258-427d-4608-f57f-7f78e4435f80","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-12-07 14:40:05.991954: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_5/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"509/509 [==============================] - ETA: 0s - loss: 5.9022 - accuracy: 0.0731 - mse: 0.0050\nEpoch 1: val_accuracy improved from -inf to 0.50330, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 653s 814ms/step - loss: 5.9022 - accuracy: 0.0731 - mse: 0.0050 - val_loss: 4.8011 - val_accuracy: 0.5033 - val_mse: 0.0049 - lr: 1.0000e-04\nEpoch 2/50\n509/509 [==============================] - ETA: 0s - loss: 3.3443 - accuracy: 0.4075 - mse: 0.0038\nEpoch 2: val_accuracy improved from 0.50330 to 0.82266, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 397s 780ms/step - loss: 3.3443 - accuracy: 0.4075 - mse: 0.0038 - val_loss: 1.5830 - val_accuracy: 0.8227 - val_mse: 0.0017 - lr: 1.0000e-04\nEpoch 3/50\n509/509 [==============================] - ETA: 0s - loss: 1.9610 - accuracy: 0.6887 - mse: 0.0024\nEpoch 3: val_accuracy improved from 0.82266 to 0.87066, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 398s 781ms/step - loss: 1.9610 - accuracy: 0.6887 - mse: 0.0024 - val_loss: 1.1690 - val_accuracy: 0.8707 - val_mse: 0.0011 - lr: 1.0000e-04\nEpoch 4/50\n509/509 [==============================] - ETA: 0s - loss: 1.3146 - accuracy: 0.8140 - mse: 0.0015\nEpoch 4: val_accuracy improved from 0.87066 to 0.89317, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 398s 781ms/step - loss: 1.3146 - accuracy: 0.8140 - mse: 0.0015 - val_loss: 0.9271 - val_accuracy: 0.8932 - val_mse: 8.6385e-04 - lr: 1.0000e-04\nEpoch 5/50\n509/509 [==============================] - ETA: 0s - loss: 0.9852 - accuracy: 0.8751 - mse: 0.0010\nEpoch 5: val_accuracy improved from 0.89317 to 0.90548, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 400s 785ms/step - loss: 0.9852 - accuracy: 0.8751 - mse: 0.0010 - val_loss: 0.8021 - val_accuracy: 0.9055 - val_mse: 7.4796e-04 - lr: 1.0000e-04\nEpoch 6/50\n509/509 [==============================] - ETA: 0s - loss: 0.7913 - accuracy: 0.9074 - mse: 7.9004e-04\nEpoch 6: val_accuracy improved from 0.90548 to 0.90971, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 400s 785ms/step - loss: 0.7913 - accuracy: 0.9074 - mse: 7.9004e-04 - val_loss: 0.7321 - val_accuracy: 0.9097 - val_mse: 7.0123e-04 - lr: 1.0000e-04\nEpoch 7/50\n509/509 [==============================] - ETA: 0s - loss: 0.6724 - accuracy: 0.9218 - mse: 6.4339e-04\nEpoch 7: val_accuracy did not improve from 0.90971\n509/509 [==============================] - 399s 783ms/step - loss: 0.6724 - accuracy: 0.9218 - mse: 6.4339e-04 - val_loss: 0.7113 - val_accuracy: 0.9005 - val_mse: 7.5093e-04 - lr: 1.0000e-04\nEpoch 8/50\n509/509 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.9336 - mse: 5.5340e-04\nEpoch 8: val_accuracy did not improve from 0.90971\n509/509 [==============================] - 400s 785ms/step - loss: 0.5813 - accuracy: 0.9336 - mse: 5.5340e-04 - val_loss: 0.6790 - val_accuracy: 0.9020 - val_mse: 7.5450e-04 - lr: 1.0000e-04\nEpoch 9/50\n509/509 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.9425 - mse: 4.7554e-04\nEpoch 9: val_accuracy did not improve from 0.90971\n509/509 [==============================] - 399s 782ms/step - loss: 0.5078 - accuracy: 0.9425 - mse: 4.7554e-04 - val_loss: 0.6604 - val_accuracy: 0.9032 - val_mse: 7.5786e-04 - lr: 1.0000e-04\nEpoch 10/50\n509/509 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.9474 - mse: 4.3703e-04\nEpoch 10: val_accuracy did not improve from 0.90971\n\nEpoch 10: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n509/509 [==============================] - 400s 784ms/step - loss: 0.4583 - accuracy: 0.9474 - mse: 4.3703e-04 - val_loss: 0.6268 - val_accuracy: 0.9056 - val_mse: 7.4436e-04 - lr: 1.0000e-04\nEpoch 11/50\n509/509 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.9660 - mse: 2.8564e-04\nEpoch 11: val_accuracy improved from 0.90971 to 0.93981, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 401s 787ms/step - loss: 0.3782 - accuracy: 0.9660 - mse: 2.8564e-04 - val_loss: 0.4947 - val_accuracy: 0.9398 - val_mse: 4.8710e-04 - lr: 1.0000e-05\nEpoch 12/50\n509/509 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.9772 - mse: 1.9189e-04\nEpoch 12: val_accuracy did not improve from 0.93981\n509/509 [==============================] - 397s 779ms/step - loss: 0.3326 - accuracy: 0.9772 - mse: 1.9189e-04 - val_loss: 0.4861 - val_accuracy: 0.9398 - val_mse: 4.7562e-04 - lr: 1.0000e-05\nEpoch 13/50\n509/509 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.9811 - mse: 1.6017e-04\nEpoch 13: val_accuracy improved from 0.93981 to 0.94105, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 397s 780ms/step - loss: 0.3142 - accuracy: 0.9811 - mse: 1.6017e-04 - val_loss: 0.4831 - val_accuracy: 0.9411 - val_mse: 4.7364e-04 - lr: 1.0000e-05\nEpoch 14/50\n509/509 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.9838 - mse: 1.3049e-04\nEpoch 14: val_accuracy did not improve from 0.94105\n509/509 [==============================] - 396s 778ms/step - loss: 0.2990 - accuracy: 0.9838 - mse: 1.3049e-04 - val_loss: 0.4810 - val_accuracy: 0.9403 - val_mse: 4.7577e-04 - lr: 1.0000e-05\nEpoch 15/50\n509/509 [==============================] - ETA: 0s - loss: 0.2905 - accuracy: 0.9858 - mse: 1.2196e-04\nEpoch 15: val_accuracy improved from 0.94105 to 0.94167, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 398s 781ms/step - loss: 0.2905 - accuracy: 0.9858 - mse: 1.2196e-04 - val_loss: 0.4774 - val_accuracy: 0.9417 - val_mse: 4.6986e-04 - lr: 1.0000e-05\nEpoch 16/50\n509/509 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.9844 - mse: 1.3158e-04\nEpoch 16: val_accuracy improved from 0.94167 to 0.94192, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 398s 781ms/step - loss: 0.2888 - accuracy: 0.9844 - mse: 1.3158e-04 - val_loss: 0.4755 - val_accuracy: 0.9419 - val_mse: 4.7346e-04 - lr: 1.0000e-05\nEpoch 17/50\n509/509 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.9874 - mse: 1.0197e-04\nEpoch 17: val_accuracy improved from 0.94192 to 0.94453, saving model to DenseNet201_Modified_MHSimamCBAM_Stanford.h5\n509/509 [==============================] - 397s 780ms/step - loss: 0.2729 - accuracy: 0.9874 - mse: 1.0197e-04 - val_loss: 0.4776 - val_accuracy: 0.9445 - val_mse: 4.7052e-04 - lr: 1.0000e-05\nEpoch 18/50\n509/509 [==============================] - ETA: 0s - loss: 0.2652 - accuracy: 0.9892 - mse: 9.6284e-05\nEpoch 18: val_accuracy did not improve from 0.94453\n509/509 [==============================] - 397s 780ms/step - loss: 0.2652 - accuracy: 0.9892 - mse: 9.6284e-05 - val_loss: 0.4759 - val_accuracy: 0.9403 - val_mse: 4.8691e-04 - lr: 1.0000e-05\nEpoch 19/50\n509/509 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.9888 - mse: 9.3627e-05\nEpoch 19: val_accuracy did not improve from 0.94453\n509/509 [==============================] - 399s 783ms/step - loss: 0.2603 - accuracy: 0.9888 - mse: 9.3627e-05 - val_loss: 0.4777 - val_accuracy: 0.9391 - val_mse: 4.9494e-04 - lr: 1.0000e-05\nEpoch 20/50\n509/509 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9907 - mse: 8.0242e-05\nEpoch 20: val_accuracy did not improve from 0.94453\n509/509 [==============================] - 398s 781ms/step - loss: 0.2500 - accuracy: 0.9907 - mse: 8.0242e-05 - val_loss: 0.4657 - val_accuracy: 0.9414 - val_mse: 4.7395e-04 - lr: 1.0000e-05\nEpoch 21/50\n509/509 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.9908 - mse: 7.4693e-05\nEpoch 21: val_accuracy did not improve from 0.94453\n\nEpoch 21: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n509/509 [==============================] - 398s 781ms/step - loss: 0.2435 - accuracy: 0.9908 - mse: 7.4693e-05 - val_loss: 0.4651 - val_accuracy: 0.9422 - val_mse: 4.7491e-04 - lr: 1.0000e-05\nEpoch 22/50\n509/509 [==============================] - ETA: 0s - loss: 0.2389 - accuracy: 0.9928 - mse: 6.9300e-05\nEpoch 22: val_accuracy did not improve from 0.94453\n509/509 [==============================] - 398s 780ms/step - loss: 0.2389 - accuracy: 0.9928 - mse: 6.9300e-05 - val_loss: 0.4636 - val_accuracy: 0.9429 - val_mse: 4.7388e-04 - lr: 1.0000e-06\nEpoch 23/50\n509/509 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9915 - mse: 6.9768e-05\nEpoch 23: val_accuracy did not improve from 0.94453\n509/509 [==============================] - 398s 781ms/step - loss: 0.2377 - accuracy: 0.9915 - mse: 6.9768e-05 - val_loss: 0.4632 - val_accuracy: 0.9430 - val_mse: 4.7390e-04 - lr: 1.0000e-06\nEpoch 24/50\n509/509 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.9920 - mse: 6.6361e-05\nEpoch 24: val_accuracy did not improve from 0.94453\n509/509 [==============================] - 399s 782ms/step - loss: 0.2361 - accuracy: 0.9920 - mse: 6.6361e-05 - val_loss: 0.4632 - val_accuracy: 0.9422 - val_mse: 4.7363e-04 - lr: 1.0000e-06\nEpoch 25/50\n509/509 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9921 - mse: 6.9144e-05\nEpoch 25: val_accuracy did not improve from 0.94453\n\nEpoch 25: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n509/509 [==============================] - 398s 781ms/step - loss: 0.2368 - accuracy: 0.9921 - mse: 6.9144e-05 - val_loss: 0.4621 - val_accuracy: 0.9423 - val_mse: 4.7148e-04 - lr: 1.0000e-06\nEpoch 25: early stopping\nPreprocessing completed. Time taken: 10214.611245393753 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"import IPython\nIPython.display.FileLink('DenseNet201_Modified_MHSimamCBAM_Stanford.weights.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T17:29:22.664886Z","iopub.execute_input":"2023-12-07T17:29:22.665322Z","iopub.status.idle":"2023-12-07T17:29:22.673107Z","shell.execute_reply.started":"2023-12-07T17:29:22.665290Z","shell.execute_reply":"2023-12-07T17:29:22.672133Z"},"id":"_bKY3o1BvR1Q","outputId":"c5322591-414c-4c52-fc79-30e8b17fca33","trusted":true},"execution_count":null,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/DenseNet201_Modified_MHSimamCBAM_Stanford.h5","text/html":"<a href='DenseNet201_Modified_MHSimamCBAM_Stanford.h5' target='_blank'>DenseNet201_Modified_MHSimamCBAM_Stanford.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"test_result = model1.evaluate(test_generator)\n#                             steps=test_generator.samples // batch_size)\ntest_loss = test_result[0]\ntest_accuracy = test_result[1]\nprint('Test Loss:', test_loss)\nprint('Test Accuracy:', test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T17:31:28.722697Z","iopub.execute_input":"2023-12-07T17:31:28.723101Z","iopub.status.idle":"2023-12-07T17:32:41.092134Z","shell.execute_reply.started":"2023-12-07T17:31:28.723069Z","shell.execute_reply":"2023-12-07T17:32:41.091249Z"},"id":"0PMnDRfBvR1Q","outputId":"e3338377-39d3-4668-a237-cc29f73a9712","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"503/503 [==============================] - 72s 143ms/step - loss: 0.4621 - accuracy: 0.9423 - mse: 4.7148e-04\nTest Loss: 0.462101548910141\nTest Accuracy: 0.9422957301139832\n","output_type":"stream"}]},{"cell_type":"code","source":"model1.load_weights(\"/kaggle/input/acc94-45-94-47-ep17-2-dnet201-mhsimsamnet/Acc94.45__94.47_ep172_DenseNet201_Modified_MHSimamCBAM_Stanford.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:46:20.063019Z","iopub.execute_input":"2023-12-17T15:46:20.063361Z","iopub.status.idle":"2023-12-17T15:46:23.665951Z","shell.execute_reply.started":"2023-12-17T15:46:20.063332Z","shell.execute_reply":"2023-12-17T15:46:23.665001Z"},"id":"oUKLoE1BvR1R","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_result = model1.evaluate(test_generator)\n#                             steps=test_generator.samples // batch_size)\ntest_loss = test_result[0]\ntest_accuracy = test_result[1]\nprint('Test Loss:', test_loss)\nprint('Test Accuracy:', test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:46:23.667090Z","iopub.execute_input":"2023-12-17T15:46:23.667402Z","iopub.status.idle":"2023-12-17T15:48:32.658038Z","shell.execute_reply.started":"2023-12-17T15:46:23.667376Z","shell.execute_reply":"2023-12-17T15:48:32.657023Z"},"id":"0EEuiiA6vR1R","outputId":"34231c91-464f-4e95-c670-aeff082f5239","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"503/503 [==============================] - 129s 215ms/step - loss: 0.4659 - accuracy: 0.9447 - mse: 4.6506e-04\nTest Loss: 0.46593818068504333\nTest Accuracy: 0.944658637046814\n","output_type":"stream"}]},{"cell_type":"code","source":"train_class_names = sorted(list(train_generator.class_indices.keys()))\n\ntest_class_names = sorted(list(test_generator.class_indices.keys()))\n\nassert train_class_names == test_class_names, \"Class names in train and test datasets don't match!\"\n\nlabels = train_class_names","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:49:38.618357Z","iopub.execute_input":"2023-12-17T15:49:38.618751Z","iopub.status.idle":"2023-12-17T15:49:38.624094Z","shell.execute_reply.started":"2023-12-17T15:49:38.618720Z","shell.execute_reply":"2023-12-17T15:49:38.623116Z"},"id":"gTvqWO1xvR1S","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming you have the ground truth labels for the test data in a variable called 'true_labels'\ntrue_labels = test_generator.classes\n\n# Generate predictions for the test data\npredictions = model1.predict(test_generator)\npredicted_labels = np.argmax(predictions, axis=1)\n\n# Define class labels (replace with your actual class names)\nlabels = train_class_names  # Replace with your class names\n\n# Generate the confusion matrix\ncm = confusion_matrix(true_labels, predicted_labels)\ncmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:49:40.684399Z","iopub.execute_input":"2023-12-17T15:49:40.685053Z","iopub.status.idle":"2023-12-17T15:50:57.364572Z","shell.execute_reply.started":"2023-12-17T15:49:40.685022Z","shell.execute_reply":"2023-12-17T15:50:57.363411Z"},"id":"7id4TTe1vR1S","outputId":"26c0dc38-13dc-4552-eadb-4088ba8f5343","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"503/503 [==============================] - 76s 136ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate the classification report\nreport = classification_report(true_labels, predicted_labels)\n\nprint(\"Confusion Matrix:\")\nprint(cm)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:50:57.366369Z","iopub.execute_input":"2023-12-17T15:50:57.366687Z","iopub.status.idle":"2023-12-17T15:50:57.396086Z","shell.execute_reply.started":"2023-12-17T15:50:57.366661Z","shell.execute_reply":"2023-12-17T15:50:57.395094Z"},"id":"KIVjeLdRvR1S","outputId":"4e223d20-ad22-49e3-9fda-b823e217bf06","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Confusion Matrix:\n[[42  0  0 ...  0  0  0]\n [ 0 32  0 ...  0  0  0]\n [ 0  0 33 ...  0  0  0]\n ...\n [ 0  0  0 ... 41  0  0]\n [ 0  0  0 ...  0 44  0]\n [ 0  0  0 ...  0  0 27]]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Classification Report:\")\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:50:57.397105Z","iopub.execute_input":"2023-12-17T15:50:57.397375Z","iopub.status.idle":"2023-12-17T15:50:57.402090Z","shell.execute_reply.started":"2023-12-17T15:50:57.397352Z","shell.execute_reply":"2023-12-17T15:50:57.401207Z"},"id":"Eb-YB4f2vR1T","outputId":"6fa944ac-9f0c-481c-d2dc-aa1919e97a2b","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.95      0.93        44\n           1       0.91      0.97      0.94        33\n           2       1.00      1.00      1.00        33\n           3       0.98      0.98      0.98        42\n           4       1.00      0.97      0.99        39\n           5       0.81      0.90      0.85        39\n           6       0.88      0.83      0.85        42\n           7       0.98      1.00      0.99        43\n           8       1.00      0.98      0.99        41\n           9       0.96      0.98      0.97        44\n          10       0.98      1.00      0.99        44\n          11       0.98      1.00      0.99        44\n          12       0.92      0.87      0.89        38\n          13       0.98      1.00      0.99        43\n          14       1.00      1.00      1.00        42\n          15       0.93      0.93      0.93        45\n          16       1.00      1.00      1.00        42\n          17       0.98      1.00      0.99        45\n          18       1.00      0.96      0.98        45\n          19       1.00      1.00      1.00        37\n          20       1.00      1.00      1.00        42\n          21       0.98      1.00      0.99        41\n          22       0.89      0.81      0.85        68\n          23       0.97      0.94      0.96        36\n          24       1.00      0.83      0.91        42\n          25       1.00      1.00      1.00        44\n          26       0.93      0.97      0.95        40\n          27       0.93      0.98      0.96        44\n          28       0.95      0.97      0.96        39\n          29       0.95      0.88      0.92        43\n          30       0.95      0.98      0.96        42\n          31       1.00      0.93      0.96        41\n          32       0.97      0.92      0.95        39\n          33       0.93      0.97      0.95        38\n          34       0.72      0.93      0.81        41\n          35       0.98      1.00      0.99        41\n          36       1.00      1.00      1.00        42\n          37       0.98      0.98      0.98        43\n          38       0.95      0.90      0.93        42\n          39       1.00      0.97      0.98        33\n          40       1.00      0.93      0.96        42\n          41       0.92      0.96      0.94        24\n          42       0.93      1.00      0.97        43\n          43       0.97      0.97      0.97        39\n          44       1.00      1.00      1.00        42\n          45       0.79      0.79      0.79        42\n          46       1.00      0.90      0.95        42\n          47       1.00      1.00      1.00        34\n          48       1.00      0.97      0.98        32\n          49       0.93      1.00      0.96        40\n          50       1.00      1.00      1.00        46\n          51       1.00      0.98      0.99        44\n          52       1.00      1.00      1.00        43\n          53       0.98      1.00      0.99        44\n          54       0.93      0.96      0.95        45\n          55       0.95      0.90      0.93        42\n          56       0.98      0.93      0.95        43\n          57       0.90      0.97      0.93        36\n          58       0.98      0.95      0.96        43\n          59       1.00      0.97      0.99        35\n          60       1.00      1.00      1.00        44\n          61       0.98      1.00      0.99        42\n          62       1.00      1.00      1.00        42\n          63       1.00      1.00      1.00        39\n          64       1.00      1.00      1.00        36\n          65       0.97      0.97      0.97        29\n          66       0.97      0.97      0.97        36\n          67       0.89      0.79      0.84        43\n          68       0.94      1.00      0.97        44\n          69       1.00      0.96      0.98        48\n          70       1.00      0.98      0.99        45\n          71       1.00      0.97      0.99        36\n          72       1.00      1.00      1.00        43\n          73       1.00      1.00      1.00        44\n          74       0.85      1.00      0.92        41\n          75       1.00      0.98      0.99        47\n          76       1.00      1.00      1.00        42\n          77       1.00      0.97      0.99        38\n          78       0.68      0.75      0.71        40\n          79       0.92      1.00      0.96        44\n          80       0.96      0.98      0.97        46\n          81       0.98      1.00      0.99        44\n          82       1.00      0.98      0.99        43\n          83       0.90      0.88      0.89        41\n          84       0.93      0.93      0.93        30\n          85       0.92      0.95      0.94        38\n          86       0.95      0.86      0.90        44\n          87       1.00      1.00      1.00        41\n          88       0.90      0.96      0.92        45\n          89       0.73      0.79      0.76        42\n          90       0.90      0.83      0.86        42\n          91       0.90      0.95      0.92        38\n          92       1.00      0.96      0.98        46\n          93       0.93      1.00      0.97        42\n          94       0.92      0.88      0.90        40\n          95       1.00      0.97      0.99        38\n          96       1.00      0.95      0.97        38\n          97       0.93      0.98      0.95        43\n          98       1.00      0.95      0.98        43\n          99       0.98      1.00      0.99        40\n         100       0.69      0.68      0.68        40\n         101       0.98      0.98      0.98        43\n         102       1.00      1.00      1.00        46\n         103       1.00      0.98      0.99        42\n         104       1.00      1.00      1.00        41\n         105       1.00      0.98      0.99        45\n         106       1.00      1.00      1.00        43\n         107       1.00      1.00      1.00        40\n         108       0.86      0.94      0.90        32\n         109       0.96      0.98      0.97        46\n         110       0.97      0.79      0.87        42\n         111       0.84      0.76      0.80        42\n         112       0.97      0.95      0.96        39\n         113       0.98      0.98      0.98        45\n         114       0.85      0.85      0.85        39\n         115       0.97      1.00      0.99        34\n         116       0.97      0.97      0.97        35\n         117       0.98      0.98      0.98        41\n         118       0.93      0.95      0.94        42\n         119       0.87      0.95      0.91        43\n         120       0.95      0.93      0.94        41\n         121       0.94      0.77      0.85        44\n         122       1.00      1.00      1.00        41\n         123       1.00      0.98      0.99        42\n         124       1.00      0.98      0.99        44\n         125       0.98      1.00      0.99        41\n         126       0.80      0.98      0.88        41\n         127       1.00      0.97      0.99        38\n         128       1.00      0.97      0.99        40\n         129       0.97      0.94      0.96        36\n         130       1.00      1.00      1.00        42\n         131       0.91      1.00      0.95        39\n         132       1.00      0.91      0.96        35\n         133       0.78      0.74      0.76        34\n         134       0.79      0.83      0.81        46\n         135       0.91      0.93      0.92        44\n         136       0.87      0.84      0.86        32\n         137       0.84      0.88      0.86        43\n         138       0.97      1.00      0.99        35\n         139       0.95      1.00      0.98        42\n         140       1.00      0.97      0.99        37\n         141       0.97      0.88      0.92        40\n         142       1.00      1.00      1.00        42\n         143       0.98      1.00      0.99        43\n         144       1.00      1.00      1.00        41\n         145       0.98      0.98      0.98        44\n         146       0.88      0.88      0.88        40\n         147       0.97      0.90      0.93        39\n         148       0.94      0.98      0.96        46\n         149       0.88      0.97      0.92        37\n         150       1.00      1.00      1.00        44\n         151       0.98      0.95      0.97        44\n         152       1.00      1.00      1.00        44\n         153       1.00      1.00      1.00        36\n         154       0.93      0.98      0.95        43\n         155       0.81      0.68      0.74        37\n         156       1.00      1.00      1.00        44\n         157       0.43      0.52      0.47        29\n         158       0.80      0.96      0.87        45\n         159       0.93      1.00      0.96        41\n         160       0.97      1.00      0.99        38\n         161       0.97      0.95      0.96        40\n         162       0.74      0.89      0.81        38\n         163       1.00      0.90      0.95        39\n         164       0.93      0.98      0.95        42\n         165       0.51      0.51      0.51        35\n         166       0.98      0.96      0.97        45\n         167       1.00      0.91      0.95        44\n         168       0.95      0.86      0.90        43\n         169       0.86      0.70      0.78        44\n         170       0.96      1.00      0.98        43\n         171       0.98      1.00      0.99        40\n         172       0.97      0.95      0.96        37\n         173       1.00      0.98      0.99        48\n         174       0.91      0.93      0.92        45\n         175       0.98      0.95      0.96        43\n         176       1.00      1.00      1.00        45\n         177       0.96      1.00      0.98        45\n         178       0.73      0.75      0.74        40\n         179       0.77      0.81      0.79        42\n         180       0.98      1.00      0.99        43\n         181       0.95      0.98      0.96        42\n         182       0.93      0.93      0.93        44\n         183       1.00      0.85      0.92        39\n         184       1.00      0.95      0.98        44\n         185       0.92      0.85      0.89        41\n         186       0.97      0.93      0.95        41\n         187       0.95      1.00      0.97        38\n         188       0.98      1.00      0.99        40\n         189       1.00      1.00      1.00        39\n         190       1.00      1.00      1.00        43\n         191       1.00      0.96      0.98        45\n         192       0.95      1.00      0.98        41\n         193       1.00      0.98      0.99        42\n         194       0.98      0.96      0.97        46\n         195       1.00      1.00      1.00        27\n\n    accuracy                           0.94      8041\n   macro avg       0.95      0.94      0.94      8041\nweighted avg       0.95      0.94      0.94      8041\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extracting metrics using classification_report\nmetrics = classification_report(true_labels, predicted_labels, output_dict=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:56:03.876792Z","iopub.execute_input":"2023-12-17T15:56:03.877192Z","iopub.status.idle":"2023-12-17T15:56:03.904795Z","shell.execute_reply.started":"2023-12-17T15:56:03.877150Z","shell.execute_reply":"2023-12-17T15:56:03.904008Z"},"id":"KQwszJNLvR1T","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate average metrics for all classes\navg_precision = metrics['macro avg']['precision']\navg_recall = metrics['macro avg']['recall']\navg_f1_score = metrics['macro avg']['f1-score']\n\nprint(\"Average Precision:\", avg_precision)\nprint(\"Average Recall:\", avg_recall)\nprint(\"Average F1-Score:\", avg_f1_score)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T15:56:05.619884Z","iopub.execute_input":"2023-12-17T15:56:05.620230Z","iopub.status.idle":"2023-12-17T15:56:05.626209Z","shell.execute_reply.started":"2023-12-17T15:56:05.620203Z","shell.execute_reply":"2023-12-17T15:56:05.625249Z"},"id":"fAzMAanSvR1T","outputId":"38dd9a0a-01ac-4133-9e31-22cad2892631","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Average Precision: 0.9453354454913759\nAverage Recall: 0.9438193369190698\nAverage F1-Score: 0.9436849357553574\n","output_type":"stream"}]}]}