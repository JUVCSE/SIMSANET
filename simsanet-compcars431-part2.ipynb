{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6464632,"sourceType":"datasetVersion","datasetId":3733520},{"sourceId":7164786,"sourceType":"datasetVersion","datasetId":4138748},{"sourceId":6518685,"sourceType":"datasetVersion","datasetId":3768406}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"train_dir = \"/kaggle/input/compcars431modelstraintest/Compcars431ModelsTrainTest/train\"\ntest_dir = \"/kaggle/input/compcars431modelstraintest/Compcars431ModelsTrainTest/val\"","metadata":{"id":"Z9CkzTAjG59r","execution":{"iopub.status.busy":"2024-08-17T03:32:23.251572Z","iopub.execute_input":"2024-08-17T03:32:23.251954Z","iopub.status.idle":"2024-08-17T03:32:23.262907Z","shell.execute_reply.started":"2024-08-17T03:32:23.251925Z","shell.execute_reply":"2024-08-17T03:32:23.262091Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout, InputLayer, BatchNormalization, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\nfrom keras import regularizers\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:32:24.226305Z","iopub.execute_input":"2024-08-17T03:32:24.227163Z","iopub.status.idle":"2024-08-17T03:32:36.479399Z","shell.execute_reply.started":"2024-08-17T03:32:24.227130Z","shell.execute_reply":"2024-08-17T03:32:36.478433Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-08-17 03:32:26.398801: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-17 03:32:26.398905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-17 03:32:26.524584: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"img_width, img_height = 400, 400\nbatch_size = 16\nepochs = 100\nnum_classes = 431","metadata":{"id":"hH0SAjDmKY09","execution":{"iopub.status.busy":"2024-08-17T03:32:50.500543Z","iopub.execute_input":"2024-08-17T03:32:50.501430Z","iopub.status.idle":"2024-08-17T03:32:50.505919Z","shell.execute_reply.started":"2024-08-17T03:32:50.501371Z","shell.execute_reply":"2024-08-17T03:32:50.504970Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator( rescale=1./255, rotation_range=25, width_shift_range=0.25, \n                                   height_shift_range=0.25, shear_range=0.25, zoom_range=0.25, \n                                   horizontal_flip=True, fill_mode='nearest' )\n        \ntest_datagen = ImageDataGenerator(rescale=1.0 / 255)\n\ntrain_generator = train_datagen.flow_from_directory( train_dir, \n                                                    target_size=(img_width, img_height), \n                                                    batch_size=batch_size, class_mode='categorical', \n                                                    shuffle=True)\n\ntest_generator = test_datagen.flow_from_directory( test_dir, \n                                                  target_size=(img_width, img_height), \n                                                  batch_size=batch_size, class_mode='categorical', \n                                                  shuffle=False )","metadata":{"id":"VeuMqX4EKdeq","execution":{"iopub.status.busy":"2024-08-17T03:32:52.682887Z","iopub.execute_input":"2024-08-17T03:32:52.683621Z","iopub.status.idle":"2024-08-17T03:32:55.481124Z","shell.execute_reply.started":"2024-08-17T03:32:52.683588Z","shell.execute_reply":"2024-08-17T03:32:55.480366Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 36334 images belonging to 431 classes.\nFound 15749 images belonging to 431 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\nfrom tensorflow.keras.layers import *","metadata":{"id":"Upd4zQZDKd5f","execution":{"iopub.status.busy":"2024-08-17T03:32:55.482693Z","iopub.execute_input":"2024-08-17T03:32:55.482963Z","iopub.status.idle":"2024-08-17T03:32:55.487302Z","shell.execute_reply.started":"2024-08-17T03:32:55.482939Z","shell.execute_reply":"2024-08-17T03:32:55.486353Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"num_heads = 5\nreduction_ratio = 8\ndropout_rate = 0.02\nl2_reg = 0.001\nsimam_lambda = 0.0001","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:05.343893Z","iopub.execute_input":"2024-08-17T03:33:05.344539Z","iopub.status.idle":"2024-08-17T03:33:05.349219Z","shell.execute_reply.started":"2024-08-17T03:33:05.344507Z","shell.execute_reply":"2024-08-17T03:33:05.348289Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class SimAM(tf.keras.layers.Layer):\n    def __init__(self, eps=0.0001, activation=tf.nn.sigmoid, trainable=True, name=None, **kwargs):\n        super(SimAM, self).__init__(name=name, trainable=trainable, **kwargs)\n        self.activation = activation\n        self.eps = eps\n\n    def build(self, input_shape):\n        self.height, self.width, self.channels = input_shape[1], input_shape[2], input_shape[3]\n        self.norm = 4. / (self.height * self.width - 1)\n        super().build(input_shape)\n\n    def call(self, inputs, **kwargs):\n        minus_mu_square = tf.square(inputs - tf.reduce_mean(inputs, axis=(1, 2), keepdims=True))\n        out = minus_mu_square / tf.maximum(\n            tf.reduce_sum(minus_mu_square, axis=(1, 2), keepdims=True) * self.norm,\n            self.eps) + 0.5\n        return inputs * self.activation(out)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:12.636369Z","iopub.execute_input":"2024-08-17T03:33:12.636718Z","iopub.status.idle":"2024-08-17T03:33:12.645414Z","shell.execute_reply.started":"2024-08-17T03:33:12.636693Z","shell.execute_reply":"2024-08-17T03:33:12.644296Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CSA(layers.Layer):\n    def __init__(self, num_heads, channels, dropout_rate=0.02,l2_reg=0.001, **kwargs):\n        super(CSA, self).__init__(**kwargs)\n        self.num_heads = num_heads\n        self.head_channels = channels // num_heads\n        self.heads = []\n\n        for _ in range(num_heads):\n            self.heads.append(self.build_SA_block(channels=self.head_channels,\n                                                              dropout_rate=dropout_rate,\n                                                              l2_reg=l2_reg))\n\n        self.simam = SimAM(eps=0.0001, activation=tf.nn.sigmoid)\n        self.dropout = layers.Dropout(dropout_rate)\n        self.batch_norm = layers.BatchNormalization()\n\n    def build_SA_block(self, channels, dropout_rate, l2_reg):\n        input_tensor = tf.keras.Input(shape=(6, 6, channels))\n\n        # Channel-wise attention Global features\n        input_channels = channels\n\n        conv_before_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(input_tensor)\n\n        conv_before_attention1 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention0)\n\n        conv_before_attention2 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention0)\n\n        conv_before_attention3 = Multiply()([conv_before_attention1, conv_before_attention2])\n\n        conv_before_attention4 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention3)\n\n        conv_before_attention5 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention3)\n\n        conv_before_attention6 = Multiply()([conv_before_attention4, conv_before_attention5])\n\n        conv_before_attention7 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention6)\n\n        conv_before_attention8 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention6)\n\n        conv_before_attention9 = Multiply()([conv_before_attention7, conv_before_attention8])\n\n        conv_before_attention10 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention9)\n\n        conv_before_attention11 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(conv_before_attention9)\n\n        conv_before_attention12 = Multiply()([conv_before_attention10, conv_before_attention11])\n\n        conv_before_attention12 = Dropout(dropout_rate)(conv_before_attention12)\n\n        avg_pool = GlobalAveragePooling2D()(conv_before_attention12)\n        max_pool = GlobalMaxPooling2D()(conv_before_attention12)\n        concat = Concatenate()([avg_pool, max_pool])\n\n        sequential_attention = Reshape((1, 1, concat.shape[-1]))(concat)\n        sequential_attention = Lambda(lambda x: tf.keras.backend.repeat_elements(x, rep=6, axis=1))(sequential_attention)\n        sequential_attention = Lambda(lambda x: tf.keras.backend.repeat_elements(x, rep=6, axis=2))(sequential_attention)\n\n        sequential_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                                       depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                       padding='same')(sequential_attention)\n\n        sequential_attention1 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention0)\n\n        sequential_attention2 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention0)\n\n        sequential_attention3 = Multiply()([sequential_attention1, sequential_attention2])\n\n        sequential_attention4 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention3)\n\n        sequential_attention5 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention3)\n\n        sequential_attention6 = Multiply()([sequential_attention4, sequential_attention5])\n\n        sequential_attention7 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention6)\n\n        sequential_attention8 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention6)\n\n        sequential_attention9 = Multiply()([sequential_attention7, sequential_attention8])\n\n        sequential_attention10 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention9)\n\n        sequential_attention11 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention9)\n\n        sequential_attention12 = Multiply()([sequential_attention10, sequential_attention11])\n\n        sequential_attention12 = Dropout(dropout_rate)(sequential_attention12)\n\n        sequential_attention13 = Concatenate()([conv_before_attention12, sequential_attention12])\n\n        # Row-wise attention\n        row_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        row_attention1 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention0)\n\n        row_attention2 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention1)\n\n        row_attention3 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention2)\n\n        row_attention4 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention3)\n\n        row_attention4 = Dropout(dropout_rate)(row_attention4)\n\n        row_attention5 = Concatenate()([sequential_attention13, row_attention4])\n\n        # Column-wise attention\n        col_attention0 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        col_attention1 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention0)\n\n        col_attention2 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention1)\n\n        col_attention3 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention2)\n\n        col_attention4 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention3)\n\n        col_attention4 = Dropout(dropout_rate)(col_attention4)\n\n        col_attention5 = Concatenate()([sequential_attention13, col_attention4])\n\n        # Combine row and column attentions\n        sequential_attention14 = Multiply()([row_attention5, col_attention5])\n        sequential_attention14 = Dropout(dropout_rate)(sequential_attention14)\n\n        conv_after_attention0 = DepthwiseConv2D( kernel_size=(1, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(sequential_attention14)\n\n        conv_after_attention1 = DepthwiseConv2D( kernel_size=(1, 2), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention0)\n\n        conv_after_attention2 = DepthwiseConv2D( kernel_size=(2, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention0)\n\n        conv_after_attention3 = Multiply()([conv_after_attention1, conv_after_attention2])\n\n        conv_after_attention4 = DepthwiseConv2D( kernel_size=(1, 3), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention3)\n\n        conv_after_attention5 = DepthwiseConv2D( kernel_size=(3, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention3)\n\n        conv_after_attention6 = Multiply()([conv_after_attention4, conv_after_attention5])\n\n        conv_after_attention7 = DepthwiseConv2D( kernel_size=(1, 4), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention6)\n\n        conv_after_attention8 = DepthwiseConv2D( kernel_size=(4, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention6)\n\n        conv_after_attention9 = Multiply()([conv_after_attention7, conv_after_attention8])\n\n        conv_after_attention10 = DepthwiseConv2D( kernel_size=(1, 5), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention9)\n\n        conv_after_attention11 = DepthwiseConv2D( kernel_size=(5, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention9)\n\n        conv_after_attention12 = Multiply()([conv_after_attention10,\n                                                     conv_after_attention11])\n\n        conv_after_attention12 = Dropout(dropout_rate)(conv_after_attention12)\n\n        conv_after_attention12 = Concatenate()([conv_before_attention12, conv_after_attention12])\n\n        # Channel-wise attention local features\n        sequential_attention15 = DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                                       depthwise_initializer='he_normal',\n                                       depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                       padding='same')(conv_after_attention12)\n\n        sequential_attention16 = DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention15)\n\n        sequential_attention17 = DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention15)\n\n        sequential_attention18 = Multiply()([sequential_attention16, sequential_attention17])\n\n        sequential_attention19 = DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention18)\n\n        sequential_attention20 = DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention18)\n\n        sequential_attention21 = Multiply()([sequential_attention19, sequential_attention20])\n\n        sequential_attention22 = DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention21)\n\n        sequential_attention23 = DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention22)\n\n        sequential_attention24 = Multiply()([sequential_attention22, sequential_attention23])\n\n        sequential_attention25 = DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention24)\n\n        sequential_attention26 = DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                                        depthwise_initializer='he_normal',\n                                        depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                        padding='same')(sequential_attention24)\n\n        sequential_attention27 = Multiply()([sequential_attention25, sequential_attention26])\n\n        sequential_attention27 = Dropout(dropout_rate)(sequential_attention27)\n\n        sequential_attention28 = Concatenate()([conv_before_attention12, sequential_attention27])\n\n        # Row-wise attention\n        row_attention6= DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        row_attention7= DepthwiseConv2D(kernel_size=(1, 2), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention6)\n\n        row_attention8= DepthwiseConv2D(kernel_size=(1, 3), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention7)\n\n        row_attention9= DepthwiseConv2D(kernel_size=(1, 4), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention8)\n\n        row_attention10= DepthwiseConv2D(kernel_size=(1, 5), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(row_attention9)\n\n        row_attention10 = Dropout(dropout_rate)(row_attention10)\n        row_attention11 = Concatenate()([sequential_attention28, row_attention10])\n\n        # Column-wise attention\n        col_attention6= DepthwiseConv2D(kernel_size=(1, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(conv_before_attention12)\n\n        col_attention7= DepthwiseConv2D(kernel_size=(2, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention6)\n\n        col_attention8= DepthwiseConv2D(kernel_size=(3, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention7)\n\n        col_attention9= DepthwiseConv2D(kernel_size=(4, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention8)\n\n        col_attention10= DepthwiseConv2D(kernel_size=(5, 1), activation='sigmoid',\n                               depthwise_initializer='he_normal', depthwise_regularizer=regularizers.l2(l2_reg),\n                               padding='same')(col_attention9)\n\n        col_attention10= Dropout(dropout_rate)(col_attention10)\n        col_attention11= Concatenate()([sequential_attention28, col_attention10])\n\n        # Combine row and column attentions\n        sequential_attention29=Multiply()([row_attention11, col_attention11])\n        sequential_attention29=Dropout(dropout_rate)(sequential_attention29)\n\n        conv_after_attention13 = DepthwiseConv2D( kernel_size=(1, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(sequential_attention29)\n\n        conv_after_attention14= DepthwiseConv2D( kernel_size=(1, 2), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention13)\n\n        conv_after_attention15= DepthwiseConv2D( kernel_size=(2, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention13)\n\n        conv_after_attention16=Multiply()([conv_after_attention14, conv_after_attention15])\n\n        conv_after_attention17= DepthwiseConv2D( kernel_size=(1, 3), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention16)\n\n        conv_after_attention18= DepthwiseConv2D( kernel_size=(3, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention16)\n\n        conv_after_attention19=Multiply()([conv_after_attention17, conv_after_attention18])\n\n        conv_after_attention20= DepthwiseConv2D( kernel_size=(1, 4), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention19)\n\n        conv_after_attention21= DepthwiseConv2D( kernel_size=(4, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention19)\n\n        conv_after_attention22=Multiply()([conv_after_attention20, conv_after_attention21])\n\n        conv_after_attention23= DepthwiseConv2D( kernel_size=(1, 5), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention22)\n\n        conv_after_attention24= DepthwiseConv2D( kernel_size=(5, 1), activation='sigmoid',\n                                            depthwise_initializer='he_normal',\n                                              depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n                                            padding='same')(conv_after_attention23)\n\n        conv_after_attention25=Multiply()([conv_after_attention23,\n                                                   conv_after_attention24])\n\n        conv_after_attention25= Dropout(dropout_rate)(conv_after_attention25)\n\n        conv_after_attention25 = Concatenate()([conv_before_attention12, conv_after_attention25])\n        \n        dual_sequential_attention = Concatenate()([conv_after_attention12, conv_after_attention25])\n\n        dual_sequential_attention = BatchNormalization()(dual_sequential_attention)\n        dual_sequential_attention = Dropout(dropout_rate)(dual_sequential_attention)\n\n        return tf.keras.Model(inputs=input_tensor, outputs=dual_sequential_attention)\n\n    def call(self, inputs):\n        head_outputs = []\n\n        for i in range(self.num_heads):\n            head_input = inputs[:, :, :, i * self.head_channels:(i + 1) * self.head_channels]\n            head_output = self.heads[i](head_input)\n            head_outputs.append(head_output)\n\n        cbam_attention = Concatenate()(head_outputs)\n        simam_attention = self.simam(inputs)\n\n        fused_attention = tf.concat([cbam_attention, simam_attention], axis=-1)\n        fused_attention = self.dropout(fused_attention)\n        fused_attention = self.batch_norm(fused_attention)\n\n        return fused_attention","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:18.509686Z","iopub.execute_input":"2024-08-17T03:33:18.510074Z","iopub.status.idle":"2024-08-17T03:33:18.585264Z","shell.execute_reply.started":"2024-08-17T03:33:18.510042Z","shell.execute_reply":"2024-08-17T03:33:18.584435Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Lambda, DepthwiseConv2D, BatchNormalization, Dropout, Reshape, UpSampling2D, Multiply","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:19.854834Z","iopub.execute_input":"2024-08-17T03:33:19.855759Z","iopub.status.idle":"2024-08-17T03:33:19.860101Z","shell.execute_reply.started":"2024-08-17T03:33:19.855723Z","shell.execute_reply":"2024-08-17T03:33:19.859041Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet201\n\nbase_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nx = base_model.output\nx = BatchNormalization()(x)\nx = Dropout(0.05)(x)\nprint(x.shape)\n\nx = layers.AveragePooling2D(pool_size=2)(x)\nx = BatchNormalization()(x)\nx = Dropout(0.05)(x)\nprint(x.shape)\n\nx = SeparableConv2D( 512, kernel_size=(5, 5), activation='sigmoid',\n            depthwise_initializer='he_normal', pointwise_initializer='he_normal',\n            depthwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n            pointwise_regularizer=tf.keras.regularizers.l2(l2_reg),\n            padding='same')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.05)(x)\nprint(x.shape)\n\nx = CSA(num_heads, 512, dropout_rate, l2_reg)(x)\nx = BatchNormalization()(x)\nx = Dropout(0.05)(x)\nprint(\"attention\",x.shape)\n\nx = layers.GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = Dropout(0.05)(x)\nprint(x.shape)\n\npreds = Dense(units=196, activation='softmax')(x)\nmodel1 = tf.keras.Model(inputs=base_model.input, outputs=preds)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:24.468054Z","iopub.execute_input":"2024-08-17T03:33:24.468726Z","iopub.status.idle":"2024-08-17T03:33:37.121575Z","shell.execute_reply.started":"2024-08-17T03:33:24.468691Z","shell.execute_reply":"2024-08-17T03:33:37.120638Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m74836368/74836368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n(None, 12, 12, 1920)\n(None, 6, 6, 1920)\n(None, 6, 6, 512)\nattention (None, 6, 6, 7142)\n(None, 7142)\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in model1.layers:\n    layer.trainable = True","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:41.535509Z","iopub.execute_input":"2024-08-17T03:33:41.536167Z","iopub.status.idle":"2024-08-17T03:33:41.545427Z","shell.execute_reply.started":"2024-08-17T03:33:41.536125Z","shell.execute_reply":"2024-08-17T03:33:41.544465Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model1.load_weights(\"/kaggle/input/acc97-50-ep25-compcars431-dr-0-2/CompCars431_(dr_0.2)_Acc97.50_ep25_DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:34:36.181341Z","iopub.execute_input":"2023-12-10T01:34:36.181755Z","iopub.status.idle":"2023-12-10T01:34:39.216829Z","shell.execute_reply.started":"2023-12-10T01:34:36.181718Z","shell.execute_reply":"2023-12-10T01:34:39.215980Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model1.compile(optimizer=Adam(learning_rate = 0.00001), loss = 'categorical_crossentropy', \n              metrics=['accuracy','mse'])\n\ncheckpoint = ModelCheckpoint('DenseNet201_Modified_MHSimamCBAM_Compcars431.weights.h5', monitor='val_accuracy', \n                             save_best_only = True, save_weights_only = True, mode ='max', verbose = 2)\n\nearly_stop = EarlyStopping(monitor = 'val_accuracy', patience = 8, mode = 'max', verbose = 2)\n\nreduce_learning_rate=ReduceLROnPlateau(monitor = \"val_accuracy\", factor = 0.1, patience = 4, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:50.538371Z","iopub.execute_input":"2024-08-17T03:33:50.538764Z","iopub.status.idle":"2024-08-17T03:33:50.560925Z","shell.execute_reply.started":"2024-08-17T03:33:50.538733Z","shell.execute_reply":"2024-08-17T03:33:50.560121Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"total_params = model1.count_params()\nprint(f\"Total parameters in the model: {total_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:53.843203Z","iopub.execute_input":"2024-08-17T03:33:53.843848Z","iopub.status.idle":"2024-08-17T03:33:53.864646Z","shell.execute_reply.started":"2024-08-17T03:33:53.843815Z","shell.execute_reply":"2024-08-17T03:33:53.863640Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Total parameters in the model: 21292216\n","output_type":"stream"}]},{"cell_type":"code","source":"trainable_params = tf.reduce_sum([tf.reduce_prod(v.shape) for v in model1.trainable_variables])\nprint(f\"Trainable parameters in the model: {trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-17T03:33:54.741875Z","iopub.execute_input":"2024-08-17T03:33:54.742587Z","iopub.status.idle":"2024-08-17T03:33:55.650601Z","shell.execute_reply.started":"2024-08-17T03:33:54.742554Z","shell.execute_reply":"2024-08-17T03:33:55.649702Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Trainable parameters in the model: 20998344\n","output_type":"stream"}]},{"cell_type":"code","source":"non_trainable_params = tf.reduce_sum([tf.reduce_prod(v.shape) for v in model1.non_trainable_weights])\nprint(f\"Non-trainable parameters in the model: {non_trainable_params}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:34:40.342570Z","iopub.execute_input":"2023-12-10T01:34:40.342842Z","iopub.status.idle":"2023-12-10T01:34:40.677428Z","shell.execute_reply.started":"2023-12-10T01:34:40.342818Z","shell.execute_reply":"2023-12-10T01:34:40.676460Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Non-trainable parameters in the model: 293872\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\nhistory=model1.fit(train_generator, epochs = 50, validation_data = test_generator, \n                  callbacks = [checkpoint, early_stop, reduce_learning_rate])\n\nend_time = time.time()\npreprocessing_time = end_time - start_time\n\nprint(\"Preprocessing completed. Time taken:\", preprocessing_time, \"seconds\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T01:34:40.678588Z","iopub.execute_input":"2023-12-10T01:34:40.678893Z","iopub.status.idle":"2023-12-10T13:19:19.923399Z","shell.execute_reply.started":"2023-12-10T01:34:40.678854Z","shell.execute_reply":"2023-12-10T13:19:19.921567Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"2023-12-10 01:36:22.402123: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_5/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"2271/2271 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9855 - mse: 5.1599e-05\nEpoch 1: val_accuracy improved from -inf to 0.97663, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 2168s 841ms/step - loss: 0.1347 - accuracy: 0.9855 - mse: 5.1599e-05 - val_loss: 0.1869 - val_accuracy: 0.9766 - val_mse: 8.4892e-05 - lr: 1.0000e-05\nEpoch 2/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 0.9887 - mse: 3.8641e-05\nEpoch 2: val_accuracy improved from 0.97663 to 0.97790, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1617s 712ms/step - loss: 0.1186 - accuracy: 0.9887 - mse: 3.8641e-05 - val_loss: 0.1799 - val_accuracy: 0.9779 - val_mse: 7.9174e-05 - lr: 1.0000e-05\nEpoch 3/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9906 - mse: 3.2265e-05\nEpoch 3: val_accuracy improved from 0.97790 to 0.97917, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1606s 707ms/step - loss: 0.1102 - accuracy: 0.9906 - mse: 3.2265e-05 - val_loss: 0.1751 - val_accuracy: 0.9792 - val_mse: 7.5478e-05 - lr: 1.0000e-05\nEpoch 4/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9919 - mse: 2.8747e-05\nEpoch 4: val_accuracy did not improve from 0.97917\n2271/2271 [==============================] - 1596s 702ms/step - loss: 0.1064 - accuracy: 0.9919 - mse: 2.8747e-05 - val_loss: 0.1770 - val_accuracy: 0.9786 - val_mse: 7.7572e-05 - lr: 1.0000e-05\nEpoch 5/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9926 - mse: 2.5568e-05\nEpoch 5: val_accuracy improved from 0.97917 to 0.97974, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1597s 703ms/step - loss: 0.1006 - accuracy: 0.9926 - mse: 2.5568e-05 - val_loss: 0.1742 - val_accuracy: 0.9797 - val_mse: 7.5106e-05 - lr: 1.0000e-05\nEpoch 6/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9931 - mse: 2.4303e-05\nEpoch 6: val_accuracy improved from 0.97974 to 0.98019, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1596s 702ms/step - loss: 0.0976 - accuracy: 0.9931 - mse: 2.4303e-05 - val_loss: 0.1711 - val_accuracy: 0.9802 - val_mse: 7.4714e-05 - lr: 1.0000e-05\nEpoch 7/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9934 - mse: 2.3345e-05\nEpoch 7: val_accuracy improved from 0.98019 to 0.98171, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1595s 702ms/step - loss: 0.0950 - accuracy: 0.9934 - mse: 2.3345e-05 - val_loss: 0.1646 - val_accuracy: 0.9817 - val_mse: 7.0069e-05 - lr: 1.0000e-05\nEpoch 8/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.9935 - mse: 2.2381e-05\nEpoch 8: val_accuracy did not improve from 0.98171\n2271/2271 [==============================] - 1596s 703ms/step - loss: 0.0925 - accuracy: 0.9935 - mse: 2.2381e-05 - val_loss: 0.1615 - val_accuracy: 0.9810 - val_mse: 7.0918e-05 - lr: 1.0000e-05\nEpoch 9/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9935 - mse: 2.3327e-05\nEpoch 9: val_accuracy did not improve from 0.98171\n2271/2271 [==============================] - 1594s 702ms/step - loss: 0.0901 - accuracy: 0.9935 - mse: 2.3327e-05 - val_loss: 0.1597 - val_accuracy: 0.9810 - val_mse: 7.0916e-05 - lr: 1.0000e-05\nEpoch 10/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9938 - mse: 2.0789e-05\nEpoch 10: val_accuracy did not improve from 0.98171\n2271/2271 [==============================] - 1595s 702ms/step - loss: 0.0869 - accuracy: 0.9938 - mse: 2.0789e-05 - val_loss: 0.1591 - val_accuracy: 0.9810 - val_mse: 7.2024e-05 - lr: 1.0000e-05\nEpoch 11/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9947 - mse: 1.8628e-05\nEpoch 11: val_accuracy did not improve from 0.98171\n\nEpoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n2271/2271 [==============================] - 1594s 702ms/step - loss: 0.0824 - accuracy: 0.9947 - mse: 1.8628e-05 - val_loss: 0.1563 - val_accuracy: 0.9816 - val_mse: 6.8378e-05 - lr: 1.0000e-05\nEpoch 12/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9952 - mse: 1.7656e-05\nEpoch 12: val_accuracy improved from 0.98171 to 0.98209, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1597s 703ms/step - loss: 0.0814 - accuracy: 0.9952 - mse: 1.7656e-05 - val_loss: 0.1539 - val_accuracy: 0.9821 - val_mse: 6.6787e-05 - lr: 1.0000e-06\nEpoch 13/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9953 - mse: 1.5872e-05\nEpoch 13: val_accuracy improved from 0.98209 to 0.98254, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1597s 703ms/step - loss: 0.0785 - accuracy: 0.9953 - mse: 1.5872e-05 - val_loss: 0.1531 - val_accuracy: 0.9825 - val_mse: 6.5845e-05 - lr: 1.0000e-06\nEpoch 14/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9959 - mse: 1.5509e-05\nEpoch 14: val_accuracy did not improve from 0.98254\n2271/2271 [==============================] - 1594s 702ms/step - loss: 0.0784 - accuracy: 0.9959 - mse: 1.5509e-05 - val_loss: 0.1523 - val_accuracy: 0.9824 - val_mse: 6.5373e-05 - lr: 1.0000e-06\nEpoch 15/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9958 - mse: 1.5030e-05\nEpoch 15: val_accuracy improved from 0.98254 to 0.98286, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1597s 703ms/step - loss: 0.0777 - accuracy: 0.9958 - mse: 1.5030e-05 - val_loss: 0.1516 - val_accuracy: 0.9829 - val_mse: 6.4502e-05 - lr: 1.0000e-06\nEpoch 16/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9954 - mse: 1.6734e-05\nEpoch 16: val_accuracy did not improve from 0.98286\n2271/2271 [==============================] - 1596s 702ms/step - loss: 0.0804 - accuracy: 0.9954 - mse: 1.6734e-05 - val_loss: 0.1514 - val_accuracy: 0.9826 - val_mse: 6.4877e-05 - lr: 1.0000e-06\nEpoch 17/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9953 - mse: 1.6079e-05\nEpoch 17: val_accuracy did not improve from 0.98286\n2271/2271 [==============================] - 1594s 702ms/step - loss: 0.0782 - accuracy: 0.9953 - mse: 1.6079e-05 - val_loss: 0.1506 - val_accuracy: 0.9829 - val_mse: 6.4160e-05 - lr: 1.0000e-06\nEpoch 18/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 0.9961 - mse: 1.4110e-05\nEpoch 18: val_accuracy did not improve from 0.98286\n2271/2271 [==============================] - 1596s 702ms/step - loss: 0.0769 - accuracy: 0.9961 - mse: 1.4110e-05 - val_loss: 0.1506 - val_accuracy: 0.9828 - val_mse: 6.4205e-05 - lr: 1.0000e-06\nEpoch 19/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9955 - mse: 1.5818e-05\nEpoch 19: val_accuracy improved from 0.98286 to 0.98305, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1595s 702ms/step - loss: 0.0779 - accuracy: 0.9955 - mse: 1.5818e-05 - val_loss: 0.1500 - val_accuracy: 0.9830 - val_mse: 6.3747e-05 - lr: 1.0000e-06\nEpoch 20/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9963 - mse: 1.3653e-05\nEpoch 20: val_accuracy did not improve from 0.98305\n2271/2271 [==============================] - 1593s 701ms/step - loss: 0.0764 - accuracy: 0.9963 - mse: 1.3653e-05 - val_loss: 0.1505 - val_accuracy: 0.9829 - val_mse: 6.3753e-05 - lr: 1.0000e-06\nEpoch 21/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.9955 - mse: 1.5804e-05\nEpoch 21: val_accuracy did not improve from 0.98305\n2271/2271 [==============================] - 1595s 702ms/step - loss: 0.0765 - accuracy: 0.9955 - mse: 1.5804e-05 - val_loss: 0.1501 - val_accuracy: 0.9830 - val_mse: 6.3829e-05 - lr: 1.0000e-06\nEpoch 22/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9963 - mse: 1.3606e-05\nEpoch 22: val_accuracy improved from 0.98305 to 0.98324, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1596s 702ms/step - loss: 0.0758 - accuracy: 0.9963 - mse: 1.3606e-05 - val_loss: 0.1497 - val_accuracy: 0.9832 - val_mse: 6.3703e-05 - lr: 1.0000e-06\nEpoch 23/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.9969 - mse: 1.1574e-05\nEpoch 23: val_accuracy did not improve from 0.98324\n2271/2271 [==============================] - 1602s 705ms/step - loss: 0.0731 - accuracy: 0.9969 - mse: 1.1574e-05 - val_loss: 0.1496 - val_accuracy: 0.9832 - val_mse: 6.3638e-05 - lr: 1.0000e-06\nEpoch 24/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9963 - mse: 1.3519e-05\nEpoch 24: val_accuracy improved from 0.98324 to 0.98330, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1601s 705ms/step - loss: 0.0741 - accuracy: 0.9963 - mse: 1.3519e-05 - val_loss: 0.1490 - val_accuracy: 0.9833 - val_mse: 6.3386e-05 - lr: 1.0000e-06\nEpoch 25/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0748 - accuracy: 0.9957 - mse: 1.4894e-05\nEpoch 25: val_accuracy improved from 0.98330 to 0.98343, saving model to DenseNet201_Modified_MHSimamCBAM_Compcars431.h5\n2271/2271 [==============================] - 1605s 707ms/step - loss: 0.0748 - accuracy: 0.9957 - mse: 1.4894e-05 - val_loss: 0.1492 - val_accuracy: 0.9834 - val_mse: 6.3466e-05 - lr: 1.0000e-06\nEpoch 26/50\n2271/2271 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9964 - mse: 1.3401e-05\nEpoch 26: val_accuracy did not improve from 0.98343\n2271/2271 [==============================] - 1609s 708ms/step - loss: 0.0739 - accuracy: 0.9964 - mse: 1.3401e-05 - val_loss: 0.1487 - val_accuracy: 0.9832 - val_mse: 6.3617e-05 - lr: 1.0000e-06\nEpoch 27/50\n 239/2271 [==>...........................] - ETA: 21:50 - loss: 0.0747 - accuracy: 0.9966 - mse: 1.2960e-05","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_learning_rate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      8\u001b[0m preprocessing_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"import IPython\nIPython.display.FileLink('DenseNet201_Modified_MHSimamCBAM_Compcars431.weights.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T13:19:43.378297Z","iopub.execute_input":"2023-12-10T13:19:43.378729Z","iopub.status.idle":"2023-12-10T13:19:43.386008Z","shell.execute_reply.started":"2023-12-10T13:19:43.378684Z","shell.execute_reply":"2023-12-10T13:19:43.385104Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/DenseNet201_Modified_MHSimamCBAM_Compcars431.h5","text/html":"<a href='DenseNet201_Modified_MHSimamCBAM_Compcars431.h5' target='_blank'>DenseNet201_Modified_MHSimamCBAM_Compcars431.h5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}